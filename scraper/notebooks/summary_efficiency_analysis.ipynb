{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary Efficiency Analysis\n",
    "\n",
    "This notebook analyzes the efficiency of text summarization by comparing summary lengths to original content lengths across different posts and threads. It generates comprehensive visualizations and statistics to evaluate summarization performance.\n",
    "\n",
    "## Features\n",
    "- Calculates and visualizes summary-to-content length ratios\n",
    "- Generates thread-specific and overall statistics\n",
    "- Creates detailed plots including:\n",
    "  - Distribution of summary ratios\n",
    "  - Thread comparison scatter plots\n",
    "  - Individual thread analysis plots\n",
    "- Outputs organized in timestamped directories:\n",
    "  - `/outputs/[source]_[timestamp]/images/` - All visualizations\n",
    "  - `/outputs/[source]_[timestamp]/data/` - CSV data files\n",
    "  - `/outputs/[source]_[timestamp]/reports/` - Markdown analysis reports\n",
    "\n",
    "## Requirements\n",
    "- Elasticsearch connection (configured via environment variables)\n",
    "- Python packages: pandas, matplotlib, seaborn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from scraper.config import settings\n",
    "from scraper.outputs import ElasticsearchOutput\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import math\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "\n",
    "def setup_output_directories(slug):\n",
    "    \"\"\"\n",
    "    Create nested output directory structure for a given analysis slug.\n",
    "    Returns a dictionary of paths for different output types.\n",
    "    \"\"\"\n",
    "    # Create base outputs directory\n",
    "    base_dir = Path('outputs')\n",
    "    base_dir.mkdir(exist_ok=True)\n",
    "    \n",
    "    # Create analysis-specific directory with timestamp\n",
    "    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "    analysis_dir = base_dir / f\"{slug}_{timestamp}\"\n",
    "    analysis_dir.mkdir(exist_ok=True)\n",
    "    \n",
    "    # Create subdirectories for different output types\n",
    "    images_dir = analysis_dir / 'images'\n",
    "    images_dir.mkdir(exist_ok=True)\n",
    "    \n",
    "    data_dir = analysis_dir / 'data'\n",
    "    data_dir.mkdir(exist_ok=True)\n",
    "    \n",
    "    reports_dir = analysis_dir / 'reports'\n",
    "    reports_dir.mkdir(exist_ok=True)\n",
    "    \n",
    "    return {\n",
    "        'base': analysis_dir,\n",
    "        'images': images_dir,\n",
    "        'data': data_dir,\n",
    "        'reports': reports_dir\n",
    "    }\n",
    "\n",
    "async def analyze_post_summaries(domain):\n",
    "    es_output = ElasticsearchOutput()\n",
    "    await es_output._initialize()\n",
    "\n",
    "    query = {\n",
    "        \"query\": {\n",
    "            \"bool\": {\n",
    "                \"must\": [\n",
    "                    {\"exists\": {\"field\": \"body\"}},\n",
    "                    {\"exists\": {\"field\": \"summary\"}},\n",
    "                    {\"term\": {\"domain.keyword\": domain}}\n",
    "                ],\n",
    "                \"must_not\": [\n",
    "                    {\"term\": {\"type.keyword\": \"combined-summary\"}}\n",
    "                ]\n",
    "            }\n",
    "        },\n",
    "        \"size\": 10000\n",
    "    }\n",
    "\n",
    "    results = await es_output.es.search(index=settings.DEFAULT_INDEX, body=query)\n",
    "\n",
    "    data = []\n",
    "    for hit in results['hits']['hits']:\n",
    "        doc = hit['_source']\n",
    "        body_length = len(doc['body'].split())\n",
    "        summary_length = len(doc['summary'].split())\n",
    "        \n",
    "        if body_length > 0:\n",
    "            ratio = summary_length / body_length\n",
    "            data.append({\n",
    "                'id': hit['_id'],\n",
    "                'body_length': body_length,\n",
    "                'summary_length': summary_length,\n",
    "                'ratio': ratio,\n",
    "                'type': doc.get('type', 'unknown'),\n",
    "                'thread_url': doc.get('thread_url', 'unknown'),\n",
    "                'author': doc.get('authors', ['unknown'])[0] if doc.get('authors') else 'unknown'\n",
    "            })\n",
    "\n",
    "    await es_output._cleanup()\n",
    "    \n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "def analyze_data(df):\n",
    "    overall_stats = {\n",
    "        'avg_ratio': df['ratio'].mean(),\n",
    "        'median_ratio': df['ratio'].median(),\n",
    "        'count': len(df)\n",
    "    }\n",
    "\n",
    "    # Sort threads by post count\n",
    "    thread_counts = df['thread_url'].value_counts()\n",
    "    \n",
    "    # Calculate per-thread statistics, sorted by post count\n",
    "    thread_stats = df.groupby('thread_url').agg({\n",
    "        'ratio': ['mean', 'median', 'count'],\n",
    "        'body_length': ['mean', 'median'],\n",
    "        'summary_length': ['mean', 'median']\n",
    "    }).loc[thread_counts.index]  # This line sorts the thread_stats by post count\n",
    "\n",
    "    # Add a numbered index to thread_stats\n",
    "    thread_stats = thread_stats.reset_index()\n",
    "    thread_stats.index = range(1, len(thread_stats) + 1)\n",
    "    thread_stats.index.name = 'Thread Number'\n",
    "\n",
    "    type_stats = df.groupby('type').agg({\n",
    "        'ratio': ['mean', 'median', 'count'],\n",
    "        'body_length': ['mean', 'median'],\n",
    "        'summary_length': ['mean', 'median']\n",
    "    })\n",
    "\n",
    "    ratio_ranges = [0, 0.5, 1, 1.5, 2, float('inf')]\n",
    "    labels = [f\"{ratio_ranges[i]}-{ratio_ranges[i+1]}\" for i in range(len(ratio_ranges)-1)]\n",
    "    df['ratio_range'] = pd.cut(df['ratio'], bins=ratio_ranges, labels=labels, include_lowest=True)\n",
    "    distribution = df['ratio_range'].value_counts().sort_index()\n",
    "\n",
    "    return overall_stats, type_stats, thread_stats, distribution, df\n",
    "\n",
    "\n",
    "def set_plot_limits(df, ax, padding=0.1):\n",
    "    max_x = df['body_length'].max()\n",
    "    max_y = df['summary_length'].max()\n",
    "    limit = max(max_x, max_y) * (1 + padding)\n",
    "    ax.set_xlim(0, limit)\n",
    "    ax.set_ylim(0, limit)\n",
    "    return limit\n",
    "\n",
    "\n",
    "def generate_thread_comparison_plot(df, output_path):\n",
    "    fig, ax = plt.subplots(figsize=(12, 8))\n",
    "    \n",
    "    # Use log scale for both axes\n",
    "    ax.set_xscale('log')\n",
    "    ax.set_yscale('log')\n",
    "    \n",
    "    # Plot the data points\n",
    "    sns.scatterplot(data=df, x='body_length', y='summary_length', hue='thread_url', \n",
    "                    palette='deep', legend=False, alpha=0.6, ax=ax)\n",
    "    \n",
    "    # Set limits based on data\n",
    "    min_x, max_x = df['body_length'].min(), df['body_length'].max()\n",
    "    min_y, max_y = df['summary_length'].min(), df['summary_length'].max()\n",
    "    ax.set_xlim(max(1, min_x/2), max_x*2)\n",
    "    ax.set_ylim(max(1, min_y/2), max_y*2)\n",
    "    \n",
    "    # Add 1:1 ratio line\n",
    "    lims = [\n",
    "        max(ax.get_xlim()[0], ax.get_ylim()[0]),\n",
    "        min(ax.get_xlim()[1], ax.get_ylim()[1]),\n",
    "    ]\n",
    "    ax.plot(lims, lims, 'r--', alpha=0.5, zorder=0, label='1:1 Ratio')\n",
    "    \n",
    "    # Add other ratio lines\n",
    "    ax.plot(lims, [l*0.5 for l in lims], 'k:', alpha=0.5, zorder=0, linewidth=2, label='0.5:1 Ratio')\n",
    "    ax.plot(lims, [l*2 for l in lims], 'g-.', alpha=0.5, zorder=0, linewidth=2, label='2:1 Ratio')\n",
    "    \n",
    "    # Customize the plot\n",
    "    ax.set_title('Body Length vs Summary Length Across Threads (Log Scale)')\n",
    "    ax.set_xlabel('Body Length (words)')\n",
    "    ax.set_ylabel('Summary Length (words)')\n",
    "    ax.legend(title='Ratio Lines', loc='upper left')\n",
    "    \n",
    "    # Add grid\n",
    "    ax.grid(True, which=\"both\", ls=\"-\", alpha=0.2)\n",
    "    \n",
    "    # Add annotations for extreme and minimum points\n",
    "    extremes = pd.concat([\n",
    "        df.nlargest(5, 'body_length'),\n",
    "        df.nlargest(5, 'summary_length'),\n",
    "        df.nsmallest(5, 'body_length'),\n",
    "        df.nsmallest(5, 'summary_length')\n",
    "    ]).drop_duplicates()\n",
    "    \n",
    "    for _, row in extremes.iterrows():\n",
    "        ax.annotate(f\"{row['body_length']},{row['summary_length']}\", \n",
    "                    (row['body_length'], row['summary_length']),\n",
    "                    xytext=(5, 5), textcoords='offset points', fontsize=8, alpha=0.7)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(output_path, dpi=300)\n",
    "    plt.close()\n",
    "\n",
    "def calculate_thread_statistics(df):\n",
    "    thread_stats = df.groupby('thread_url').agg({\n",
    "        'ratio': ['mean', 'median'],\n",
    "        'author': 'first'  # Assuming the first post's author is the original author\n",
    "    }).reset_index()\n",
    "    thread_stats.columns = ['thread_url', 'mean_ratio', 'median_ratio', 'original_author']\n",
    "    return thread_stats\n",
    "\n",
    "def generate_multi_thread_plot(df, output_path, max_threads=16):\n",
    "    # Calculate thread statistics\n",
    "    thread_stats = calculate_thread_statistics(df)\n",
    "    \n",
    "    # Sort threads by post count and filter out single-post threads\n",
    "    thread_counts = df['thread_url'].value_counts()\n",
    "    multi_post_threads = thread_counts[thread_counts > 1]\n",
    "    top_threads = multi_post_threads.nlargest(max_threads).index\n",
    "\n",
    "    # Filter dataframe to include only top threads\n",
    "    df_top = df[df['thread_url'].isin(top_threads)]\n",
    "\n",
    "    # Calculate grid size\n",
    "    grid_size = math.ceil(math.sqrt(len(top_threads)))\n",
    "\n",
    "    fig, axes = plt.subplots(grid_size, grid_size, figsize=(4*grid_size, 4*grid_size))\n",
    "    fig.suptitle('Body Length vs Summary Length per Thread (Top Threads)', fontsize=16)\n",
    "\n",
    "    for i, (ax, thread) in enumerate(zip(axes.flatten(), top_threads)):\n",
    "        thread_df = df_top[df_top['thread_url'] == thread]\n",
    "        thread_stat = thread_stats[thread_stats['thread_url'] == thread].iloc[0]\n",
    "        \n",
    "        # Determine original author\n",
    "        original_author = thread_stat['original_author']\n",
    "        \n",
    "        # Plot points, differentiating original author and original post\n",
    "        for j, (index, row) in enumerate(thread_df.iterrows()):\n",
    "            if j == 0:  # Original post\n",
    "                color = 'green'\n",
    "                label = 'Original Post'\n",
    "            elif row['author'] == original_author:\n",
    "                color = 'red'\n",
    "                label = 'Original Author'\n",
    "            else:\n",
    "                color = 'blue'\n",
    "                label = None\n",
    "            \n",
    "            ax.scatter(row['body_length'], row['summary_length'], \n",
    "                       c=color, alpha=0.6, label=label)\n",
    "        \n",
    "        limit = set_plot_limits(thread_df, ax)\n",
    "        \n",
    "        # Add 1:1 ratio line\n",
    "        ax.plot([0, limit], [0, limit], 'g--', alpha=0.5, label='1:1 Ratio')\n",
    "        \n",
    "        # Add mean ratio line (more subtle)\n",
    "        mean_ratio = thread_stat['mean_ratio']\n",
    "        ax.plot([0, limit], [0, limit * mean_ratio], 'r:', alpha=0.3, label=f'Mean Ratio: {mean_ratio:.2f}')\n",
    "        \n",
    "        ax.set_title(f'Thread {i+1}: {thread_counts[thread]} posts\\nMean Ratio: {mean_ratio:.2f}', fontsize=10)\n",
    "        ax.set_xlabel('Body Length', fontsize=8)\n",
    "        ax.set_ylabel('Summary Length', fontsize=8)\n",
    "        ax.tick_params(labelsize=6)\n",
    "        \n",
    "        # Add legend with all desired items\n",
    "        handles, labels = ax.get_legend_handles_labels()\n",
    "        by_label = dict(zip(labels, handles))\n",
    "        desired_labels = ['Original Post', 'Original Author', '1:1 Ratio', f'Mean Ratio: {mean_ratio:.2f}']\n",
    "        ax.legend([by_label[label] for label in desired_labels if label in by_label],\n",
    "                  [label for label in desired_labels if label in by_label],\n",
    "                  fontsize=6, loc='upper left')\n",
    "\n",
    "    # Remove any unused subplots\n",
    "    for j in range(i+1, grid_size**2):\n",
    "        fig.delaxes(axes.flatten()[j])\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(output_path, dpi=300)\n",
    "    plt.close()\n",
    "\n",
    "def generate_markdown_report(slug, overall_stats, type_stats, thread_stats, distribution, df, output_dirs):\n",
    "    markdown = f\"# Post Summary Analysis for {slug}\\n\\n\"\n",
    "    \n",
    "    markdown += \"## Overall Statistics\\n\\n\"\n",
    "    markdown += f\"- Average summary/body length ratio: {overall_stats['avg_ratio']:.2f}\\n\"\n",
    "    markdown += f\"- Median summary/body length ratio: {overall_stats['median_ratio']:.2f}\\n\"\n",
    "    markdown += f\"- Number of posts analyzed: {overall_stats['count']}\\n\\n\"\n",
    "    \n",
    "    markdown += \"## Per-type Statistics\\n\\n\"\n",
    "    markdown += type_stats.to_markdown() + \"\\n\\n\"\n",
    "    \n",
    "    markdown += \"## Distribution of summary/body length ratios\\n\\n\"\n",
    "    for range, count in distribution.items():\n",
    "        percentage = (count / overall_stats['count']) * 100\n",
    "        markdown += f\"- {range}: {count} ({percentage:.2f}%)\\n\"\n",
    "    markdown += \"\\n\"\n",
    "    \n",
    "    # Generate plots\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    distribution.plot(kind='bar')\n",
    "    plt.title('Distribution of Summary/Body Length Ratios')\n",
    "    plt.xlabel('Ratio Range')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(output_dirs['images'] / 'distribution_plot.png')\n",
    "    plt.close()\n",
    "    \n",
    "    generate_thread_comparison_plot(df, output_dirs['images'] / 'thread_comparison_plot.png')\n",
    "    generate_multi_thread_plot(df, output_dirs['images'] / 'multi_thread_plot.png', max_threads=48)\n",
    "    \n",
    "    # Add images to markdown using relative paths\n",
    "    markdown += \"## Visualizations\\n\\n\"\n",
    "    markdown += \"### Distribution of Summary/Body Length Ratios\\n\"\n",
    "    markdown += \"![Distribution Plot](../images/distribution_plot.png)\\n\\n\"\n",
    "    markdown += \"### Body Length vs Summary Length Across Threads\\n\"\n",
    "    markdown += \"![Thread Comparison Plot](../images/thread_comparison_plot.png)\\n\\n\"\n",
    "    markdown += \"### Body Length vs Summary Length per Thread (Top Threads)\\n\"\n",
    "    markdown += \"![Multi-Thread Plot](../images/multi_thread_plot.png)\\n\\n\"\n",
    "    \n",
    "    markdown += \"## Per-thread Statistics\\n\\n\"\n",
    "    markdown += thread_stats.to_markdown() + \"\\n\\n\"\n",
    "    \n",
    "    return markdown\n",
    "\n",
    "def generate_csv(df):\n",
    "    # Sort the DataFrame by thread_url to group posts from the same thread together\n",
    "    df_sorted = df.sort_values(['thread_url', 'id'])\n",
    "    \n",
    "    # Generate CSV from the sorted DataFrame\n",
    "    return df_sorted.to_csv(index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "domains = {\n",
    "    \"delvingbitcoin\": \"https://delvingbitcoin.org/\",\n",
    "    \"bitcoindev\": \"https://mailing-list.bitcoindevs.xyz/bitcoindev/\",\n",
    "    \"lightning-dev\": \"https://lists.linuxfoundation.org/pipermail/lightning-dev/\",\n",
    "}\n",
    "source = \"lightning-dev\" # Select the domain you want to analyze\n",
    "domain = domains[source]\n",
    "\n",
    "print(f\"domain: {domain}\")\n",
    "print(f\"index: {settings.DEFAULT_INDEX}\")\n",
    "\n",
    "# setup output directories\n",
    "output_dirs = setup_output_directories(source)\n",
    "\n",
    "df = await analyze_post_summaries(domain)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overall_stats, type_stats, thread_stats, distribution, full_df = analyze_data(df)\n",
    "# Generate and save markdown report\n",
    "markdown_report = generate_markdown_report(source, overall_stats, type_stats, thread_stats, distribution, full_df, output_dirs)\n",
    "with open(output_dirs['reports'] / f\"{source}_analysis.md\", \"w\") as f:\n",
    "    f.write(markdown_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate and save CSV\n",
    "csv_output = generate_csv(full_df)\n",
    "with open(output_dirs['data'] / f\"{source}_thread_analysis.csv\", \"w\") as f:\n",
    "    f.write(csv_output)\n",
    "\n",
    "print(f\"Analysis complete. Files saved in {output_dirs['base']}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
